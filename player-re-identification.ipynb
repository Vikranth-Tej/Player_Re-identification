{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2557df68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T04:12:03.154553Z",
     "iopub.status.busy": "2025-06-30T04:12:03.154337Z",
     "iopub.status.idle": "2025-06-30T04:14:53.827297Z",
     "shell.execute_reply": "2025-06-30T04:14:53.826431Z"
    },
    "papermill": {
     "duration": 170.6774,
     "end_time": "2025-06-30T04:14:53.828737",
     "exception": false,
     "start_time": "2025-06-30T04:12:03.151337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics==8.0.196\r\n",
      "  Downloading ultralytics-8.0.196-py3-none-any.whl.metadata (31 kB)\r\n",
      "Collecting opencv-python==4.8.1.78\r\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\r\n",
      "Collecting numpy==1.24.3\r\n",
      "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\r\n",
      "Collecting scipy==1.11.3\r\n",
      "  Downloading scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting scikit-learn==1.3.0\r\n",
      "  Downloading scikit_learn-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting torch==2.0.1\r\n",
      "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\r\n",
      "Collecting torchvision==0.15.2\r\n",
      "  Downloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (3.7.2)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (11.1.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (4.67.1)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (2.2.3)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (0.12.2)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (7.0.0)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (9.0.0)\r\n",
      "Collecting thop>=0.1.1 (from ultralytics==8.0.196)\r\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.0) (1.5.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.0) (3.6.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.13.2)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.0.0 (from torch==2.0.1)\r\n",
      "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.2.0)\r\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\r\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\r\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.1)\r\n",
      "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (4.57.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (25.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.0.196) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.0.196) (2025.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (2025.4.26)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.0.196) (1.17.0)\r\n",
      "Downloading ultralytics-8.0.196-py3-none-any.whl (631 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_learn-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\r\n",
      "Downloading lit-18.1.8-py3-none-any.whl (96 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, scipy, opencv-python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, scikit-learn, triton, torch, torchvision, thop, ultralytics\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.15.2\r\n",
      "    Uninstalling scipy-1.15.2:\r\n",
      "      Successfully uninstalled scipy-1.15.2\r\n",
      "  Attempting uninstall: opencv-python\r\n",
      "    Found existing installation: opencv-python 4.11.0.86\r\n",
      "    Uninstalling opencv-python-4.11.0.86:\r\n",
      "      Successfully uninstalled opencv-python-4.11.0.86\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.2.0\r\n",
      "    Uninstalling triton-3.2.0:\r\n",
      "      Successfully uninstalled triton-3.2.0\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.6.0+cu124\r\n",
      "    Uninstalling torch-2.6.0+cu124:\r\n",
      "      Successfully uninstalled torch-2.6.0+cu124\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.21.0+cu124\r\n",
      "    Uninstalling torchvision-0.21.0+cu124:\r\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\r\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\r\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.3 which is incompatible.\r\n",
      "woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "pytorch-lightning 2.5.1.post0 requires torch>=2.1.0, but you have torch 2.0.1 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "bayesian-optimization 2.0.3 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\r\n",
      "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.11.3 which is incompatible.\r\n",
      "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\r\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.3.0 which is incompatible.\r\n",
      "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\r\n",
      "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\r\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.3.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed lit-18.1.8 numpy-1.24.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 opencv-python-4.8.1.78 scikit-learn-1.3.0 scipy-1.11.3 thop-0.1.1.post2209072238 torch-2.0.1 torchvision-0.15.2 triton-2.0.0 ultralytics-8.0.196\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics==8.0.196 opencv-python==4.8.1.78 numpy==1.24.3 scipy==1.11.3 scikit-learn==1.3.0 torch==2.0.1 torchvision==0.15.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1a9d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T04:14:53.900387Z",
     "iopub.status.busy": "2025-06-30T04:14:53.900091Z",
     "iopub.status.idle": "2025-06-30T04:15:34.968852Z",
     "shell.execute_reply": "2025-06-30T04:15:34.967869Z"
    },
    "papermill": {
     "duration": 41.106584,
     "end_time": "2025-06-30T04:15:34.970427",
     "exception": false,
     "start_time": "2025-06-30T04:14:53.863843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Single Feed Player Re-Identification System (Kaggle)\n",
      "============================================================\n",
      "✅ All files found!\n",
      "🚀 Initializing Single Feed Player Re-Identification System (Kaggle)\n",
      "✅ Loading model from: /kaggle/input/yolov11/pytorch/default/1/best.pt\n",
      "✅ System initialized successfully!\n",
      "🎬 Opening video: /kaggle/input/play-videos/15sec_input_720p.mp4\n",
      "📊 Video: 1280x720 @ 25fps (375 frames)\n",
      "🔄 Processing with enhanced re-identification...\n",
      "➕ New player 1 initialized\n",
      "➕ New player 2 initialized\n",
      "➕ New player 3 initialized\n",
      "➕ New player 4 initialized\n",
      "➕ New player 5 initialized\n",
      "➕ New player 6 initialized\n",
      "➕ New player 7 initialized\n",
      "➕ New player 8 initialized\n",
      "➕ New player 9 initialized\n",
      "➕ New player 10 initialized\n",
      "➕ New player 11 initialized\n",
      "➕ New player 12 initialized\n",
      "➕ New player 13 initialized\n",
      "➕ New player 14 initialized\n",
      "➕ New player 15 initialized\n",
      "➕ New player 16 initialized\n",
      "➕ New player 17 initialized\n",
      "➕ New player 18 initialized\n",
      "➕ New player 19 initialized\n",
      "➕ New player 20 detected\n",
      "➕ New player 21 detected\n",
      "📈 Progress: 30/375 (8.0%) - 3.9 fps\n",
      "➕ New player 22 detected\n",
      "📈 Progress: 60/375 (16.0%) - 6.1 fps\n",
      "📈 Progress: 90/375 (24.0%) - 7.4 fps\n",
      "➕ New player 23 detected\n",
      "📈 Progress: 120/375 (32.0%) - 8.3 fps\n",
      "💤 Player 2 moved to inactive\n",
      "💤 Player 18 moved to inactive\n",
      "📈 Progress: 150/375 (40.0%) - 9.0 fps\n",
      "💤 Player 14 moved to inactive\n",
      "🔄 RE-IDENTIFIED Player 14 (similarity: 0.899)\n",
      "📈 Progress: 180/375 (48.0%) - 9.5 fps\n",
      "🔄 RE-IDENTIFIED Player 2 (similarity: 0.849)\n",
      "💤 Player 5 moved to inactive\n",
      "🔄 RE-IDENTIFIED Player 5 (similarity: 0.797)\n",
      "💤 Player 14 moved to inactive\n",
      "💤 Player 7 moved to inactive\n",
      "📈 Progress: 210/375 (56.0%) - 10.0 fps\n",
      "💤 Player 1 moved to inactive\n",
      "📈 Progress: 240/375 (64.0%) - 10.4 fps\n",
      "💤 Player 13 moved to inactive\n",
      "💤 Player 10 moved to inactive\n",
      "💤 Player 19 moved to inactive\n",
      "🔄 RE-IDENTIFIED Player 13 (similarity: 0.739)\n",
      "🔄 RE-IDENTIFIED Player 10 (similarity: 0.838)\n",
      "💤 Player 2 moved to inactive\n",
      "💤 Player 16 moved to inactive\n",
      "🗑️ Removed player 18 from tracking\n",
      "📈 Progress: 270/375 (72.0%) - 10.7 fps\n",
      "🔄 RE-IDENTIFIED Player 16 (similarity: 0.932)\n",
      "🔄 RE-IDENTIFIED Player 19 (similarity: 0.975)\n",
      "🔄 RE-IDENTIFIED Player 2 (similarity: 0.867)\n",
      "🔄 RE-IDENTIFIED Player 1 (similarity: 0.850)\n",
      "🔄 RE-IDENTIFIED Player 7 (similarity: 0.771)\n",
      "📈 Progress: 300/375 (80.0%) - 11.0 fps\n",
      "🗑️ Removed player 14 from tracking\n",
      "📈 Progress: 330/375 (88.0%) - 11.2 fps\n",
      "📈 Progress: 360/375 (96.0%) - 11.4 fps\n",
      "✅ Complete! Time: 32.6s\n",
      "\n",
      "📊 TRACKING STATISTICS\n",
      "========================================\n",
      "Frames processed: 375\n",
      "Total detections: 5577\n",
      "New players: 23\n",
      "Re-identifications: 10\n",
      "Active players: 21\n",
      "Inactive players: 0\n",
      "Total unique players: 23\n",
      "✅ RE-IDENTIFICATION WORKING!\n",
      "\n",
      "👥 PLAYER DETAILS\n",
      "Player 1: 237 appearances [ACTIVE]\n",
      "Player 2: 199 appearances [ACTIVE]\n",
      "Player 3: 324 appearances [ACTIVE]\n",
      "Player 4: 262 appearances [ACTIVE]\n",
      "Player 5: 265 appearances [ACTIVE]\n",
      "Player 6: 270 appearances [ACTIVE]\n",
      "Player 7: 228 appearances [ACTIVE]\n",
      "Player 8: 341 appearances [ACTIVE]\n",
      "Player 9: 256 appearances [ACTIVE]\n",
      "Player 10: 301 appearances [ACTIVE]\n",
      "Player 11: 237 appearances [ACTIVE]\n",
      "Player 12: 203 appearances [ACTIVE]\n",
      "Player 13: 280 appearances [ACTIVE]\n",
      "Player 14: 134 appearances [INACTIVE]\n",
      "Player 15: 264 appearances [ACTIVE]\n",
      "Player 16: 301 appearances [ACTIVE]\n",
      "Player 17: 176 appearances [ACTIVE]\n",
      "Player 18: 114 appearances [INACTIVE]\n",
      "Player 19: 273 appearances [ACTIVE]\n",
      "Player 20: 223 appearances [ACTIVE]\n",
      "Player 21: 254 appearances [ACTIVE]\n",
      "Player 22: 201 appearances [ACTIVE]\n",
      "Player 23: 234 appearances [ACTIVE]\n",
      "📋 Results saved: /kaggle/working/15sec_output_reidentified_720p_results.json\n",
      "\n",
      "🎉 KAGGLE RE-IDENTIFICATION COMPLETE!\n",
      "============================================================\n",
      "📂 Output: /kaggle/working/15sec_output_reidentified_720p.mp4\n",
      "📊 Results: /kaggle/working/15sec_output_reidentified_720p_results.json\n",
      "\n",
      "✨ Features:\n",
      "   • LARGE VISIBLE Player IDs\n",
      "   • Enhanced re-identification\n",
      "   • Kaggle-optimized paths\n",
      "   • Real-time processing\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import deque\n",
    "import json\n",
    "import time\n",
    "\n",
    "class SingleFeedPlayerReID:\n",
    "    def __init__(self, model_path=None):\n",
    "        \"\"\"Initialize the Single Feed Player Re-Identification system for Kaggle\"\"\"\n",
    "        print(\"🚀 Initializing Single Feed Player Re-Identification System (Kaggle)\")\n",
    "        \n",
    "        # Kaggle model path\n",
    "        self.model_path = model_path or \"/kaggle/input/yolov11/pytorch/default/1/best.pt\"\n",
    "        \n",
    "        if not os.path.exists(self.model_path):\n",
    "            print(f\"❌ Error: Model not found at {self.model_path}\")\n",
    "            print(\"Please ensure the YOLOv11 model is uploaded to Kaggle\")\n",
    "            return\n",
    "        \n",
    "        print(f\"✅ Loading model from: {self.model_path}\")\n",
    "        self.model = YOLO(self.model_path)\n",
    "        \n",
    "        # Player tracking data\n",
    "        self.active_players = {}      # Currently visible players\n",
    "        self.inactive_players = {}    # Players who disappeared but might return\n",
    "        self.player_history = {}      # Complete history of all players\n",
    "        self.next_player_id = 1\n",
    "        \n",
    "        # Enhanced tracking parameters for better re-identification\n",
    "        self.max_disappeared = 30     # Reduced frames before moving to inactive\n",
    "        self.max_inactive_time = 120  # Frames to keep inactive players for re-identification\n",
    "        self.feature_history_size = 10 # Number of feature vectors to store\n",
    "        self.confidence_threshold = 0.25 # Lower threshold for better detection\n",
    "        \n",
    "        # Re-identification parameters - more lenient for better matching\n",
    "        self.reid_similarity_threshold = 0.65  # Lower threshold for easier re-identification\n",
    "        self.spatial_weight = 0.4     # Increased spatial weight\n",
    "        self.feature_weight = 0.6     # Reduced feature weight for more flexibility\n",
    "        \n",
    "        # Enhanced color palette for player visualization\n",
    "        self.colors = [\n",
    "            (0, 0, 255),     # Red\n",
    "            (0, 255, 0),     # Green  \n",
    "            (255, 0, 0),     # Blue\n",
    "            (0, 255, 255),   # Yellow\n",
    "            (255, 0, 255),   # Magenta\n",
    "            (255, 255, 0),   # Cyan\n",
    "            (128, 0, 128),   # Purple\n",
    "            (255, 165, 0),   # Orange\n",
    "            (0, 128, 0),     # Dark Green\n",
    "            (128, 128, 0),   # Olive\n",
    "            (0, 0, 128),     # Navy\n",
    "            (128, 0, 0),     # Maroon\n",
    "            (255, 192, 203), # Pink\n",
    "            (165, 42, 42),   # Brown\n",
    "            (64, 224, 208),  # Turquoise\n",
    "            (255, 20, 147),  # Deep Pink\n",
    "            (0, 191, 255),   # Deep Sky Blue\n",
    "            (50, 205, 50),   # Lime Green\n",
    "            (255, 69, 0),    # Red Orange\n",
    "            (138, 43, 226),  # Blue Violet\n",
    "        ]\n",
    "        \n",
    "        # Statistics tracking\n",
    "        self.stats = {\n",
    "            'total_detections': 0,\n",
    "            'reidentifications': 0,\n",
    "            'new_players': 0,\n",
    "            'frames_processed': 0\n",
    "        }\n",
    "        \n",
    "        print(\"✅ System initialized successfully!\")\n",
    "    \n",
    "    def extract_enhanced_features(self, frame, bbox):\n",
    "        \"\"\"Extract comprehensive visual features from player bounding box\"\"\"\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        \n",
    "        # Ensure coordinates are within frame bounds\n",
    "        h, w = frame.shape[:2]\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w, x2), min(h, y2)\n",
    "        \n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return np.zeros(128)  # Reduced feature size for efficiency\n",
    "        \n",
    "        # Extract player region\n",
    "        player_region = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        if player_region.size == 0:\n",
    "            return np.zeros(128)\n",
    "        \n",
    "        # Resize to standard size for consistent feature extraction\n",
    "        try:\n",
    "            player_region = cv2.resize(player_region, (32, 64))  # Smaller for efficiency\n",
    "        except:\n",
    "            return np.zeros(128)\n",
    "        \n",
    "        # 1. Color Features - RGB histograms\n",
    "        hist_b = cv2.calcHist([player_region], [0], None, [16], [0, 256])\n",
    "        hist_g = cv2.calcHist([player_region], [1], None, [16], [0, 256])\n",
    "        hist_r = cv2.calcHist([player_region], [2], None, [16], [0, 256])\n",
    "        \n",
    "        # Normalize histograms\n",
    "        hist_b = hist_b.flatten() / (hist_b.sum() + 1e-7)\n",
    "        hist_g = hist_g.flatten() / (hist_g.sum() + 1e-7)\n",
    "        hist_r = hist_r.flatten() / (hist_r.sum() + 1e-7)\n",
    "        \n",
    "        # 2. HSV color space for better color representation\n",
    "        try:\n",
    "            hsv_region = cv2.cvtColor(player_region, cv2.COLOR_BGR2HSV)\n",
    "            hist_h = cv2.calcHist([hsv_region], [0], None, [16], [0, 180])\n",
    "            hist_s = cv2.calcHist([hsv_region], [1], None, [16], [0, 256])\n",
    "            hist_v = cv2.calcHist([hsv_region], [2], None, [16], [0, 256])\n",
    "            \n",
    "            hist_h = hist_h.flatten() / (hist_h.sum() + 1e-7)\n",
    "            hist_s = hist_s.flatten() / (hist_s.sum() + 1e-7)\n",
    "            hist_v = hist_v.flatten() / (hist_v.sum() + 1e-7)\n",
    "        except:\n",
    "            hist_h = np.zeros(16)\n",
    "            hist_s = np.zeros(16)\n",
    "            hist_v = np.zeros(16)\n",
    "        \n",
    "        # 3. Simple texture features\n",
    "        try:\n",
    "            gray = cv2.cvtColor(player_region, cv2.COLOR_BGR2GRAY)\n",
    "            texture_features = [\n",
    "                np.std(gray),           # Standard deviation\n",
    "                np.mean(gray),          # Mean intensity\n",
    "                np.max(gray) - np.min(gray) if gray.size > 0 else 0,  # Range\n",
    "            ]\n",
    "            texture_features = np.array(texture_features[:16])  # Limit size\n",
    "            if len(texture_features) < 16:\n",
    "                texture_features = np.pad(texture_features, (0, 16-len(texture_features)))\n",
    "        except:\n",
    "            texture_features = np.zeros(16)\n",
    "        \n",
    "        # 4. Geometric features\n",
    "        aspect_ratio = (x2 - x1) / max(y2 - y1, 1)\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "        geometric_features = np.array([aspect_ratio, area / 10000.0])\n",
    "        \n",
    "        # Combine all features (16+16+16+16+16+16+16+2 = 128 features)\n",
    "        features = np.concatenate([\n",
    "            hist_b, hist_g, hist_r,  # RGB: 48 features\n",
    "            hist_h, hist_s, hist_v,  # HSV: 48 features\n",
    "            texture_features,        # Texture: 16 features\n",
    "            geometric_features       # Geometric: 2 features\n",
    "        ])\n",
    "        \n",
    "        # Ensure fixed size\n",
    "        if len(features) < 128:\n",
    "            features = np.pad(features, (0, 128-len(features)))\n",
    "        \n",
    "        return features[:128]\n",
    "    \n",
    "    def detect_players(self, frame):\n",
    "        \"\"\"Detect players in a frame using YOLO\"\"\"\n",
    "        try:\n",
    "            results = self.model(frame, verbose=False, conf=self.confidence_threshold)\n",
    "            detections = []\n",
    "            \n",
    "            for result in results:\n",
    "                boxes = result.boxes\n",
    "                if boxes is not None:\n",
    "                    for box in boxes:\n",
    "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                        confidence = box.conf[0].cpu().numpy()\n",
    "                        class_id = int(box.cls[0].cpu().numpy())\n",
    "                        \n",
    "                        # Filter for person detections (class 0 in COCO/YOLO)\n",
    "                        if confidence > self.confidence_threshold:\n",
    "                            width = x2 - x1\n",
    "                            height = y2 - y1\n",
    "                            aspect_ratio = width / max(height, 1)\n",
    "                            \n",
    "                            # Filter realistic human detections\n",
    "                            if (width > 5 and height > 10 and \n",
    "                                aspect_ratio > 0.2 and aspect_ratio < 3.0):\n",
    "                                \n",
    "                                detections.append({\n",
    "                                    'bbox': [x1, y1, x2, y2],\n",
    "                                    'confidence': confidence,\n",
    "                                    'center': [(x1 + x2) / 2, (y1 + y2) / 2],\n",
    "                                    'area': width * height\n",
    "                                })\n",
    "            \n",
    "            # Sort by confidence\n",
    "            detections.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "            self.stats['total_detections'] += len(detections)\n",
    "            \n",
    "            return detections\n",
    "        except Exception as e:\n",
    "            print(f\"Detection error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def calculate_similarity(self, features1, features2, center1, center2):\n",
    "        \"\"\"Calculate similarity between two player detections\"\"\"\n",
    "        try:\n",
    "            # Feature similarity (cosine similarity)\n",
    "            dot_product = np.dot(features1, features2)\n",
    "            norm1 = np.linalg.norm(features1)\n",
    "            norm2 = np.linalg.norm(features2)\n",
    "            \n",
    "            if norm1 == 0 or norm2 == 0:\n",
    "                feature_sim = 0\n",
    "            else:\n",
    "                feature_sim = dot_product / (norm1 * norm2)\n",
    "                feature_sim = max(0, feature_sim)  # Ensure non-negative\n",
    "            \n",
    "            # Spatial similarity\n",
    "            spatial_dist = np.linalg.norm(np.array(center1) - np.array(center2))\n",
    "            spatial_sim = 1 / (1 + spatial_dist / 200.0)  # Normalized spatial similarity\n",
    "            \n",
    "            # Combined similarity\n",
    "            combined_sim = (self.feature_weight * feature_sim + \n",
    "                           self.spatial_weight * spatial_sim)\n",
    "            \n",
    "            return combined_sim, feature_sim, spatial_sim\n",
    "        except:\n",
    "            return 0.0, 0.0, 0.0\n",
    "    \n",
    "    def match_detections_to_players(self, detections, frame):\n",
    "        \"\"\"Match detections to existing players with improved re-identification\"\"\"\n",
    "        if not detections:\n",
    "            # Handle disappeared players\n",
    "            for player_id in list(self.active_players.keys()):\n",
    "                self.active_players[player_id]['disappeared'] += 1\n",
    "                if self.active_players[player_id]['disappeared'] > self.max_disappeared:\n",
    "                    # Move to inactive\n",
    "                    self.inactive_players[player_id] = self.active_players[player_id]\n",
    "                    self.inactive_players[player_id]['inactive_time'] = 0\n",
    "                    del self.active_players[player_id]\n",
    "                    print(f\"💤 Player {player_id} moved to inactive pool\")\n",
    "            return\n",
    "        \n",
    "        # Extract features for all detections\n",
    "        for detection in detections:\n",
    "            detection['features'] = self.extract_enhanced_features(frame, detection['bbox'])\n",
    "        \n",
    "        # Initialize first players\n",
    "        if not self.active_players and not self.inactive_players:\n",
    "            for detection in detections:\n",
    "                player_id = self.next_player_id\n",
    "                self.next_player_id += 1\n",
    "                \n",
    "                self.active_players[player_id] = {\n",
    "                    'bbox': detection['bbox'],\n",
    "                    'center': detection['center'],\n",
    "                    'features': deque([detection['features']], maxlen=self.feature_history_size),\n",
    "                    'confidence': detection['confidence'],\n",
    "                    'disappeared': 0,\n",
    "                    'last_seen_frame': self.stats['frames_processed'],\n",
    "                    'total_detections': 1\n",
    "                }\n",
    "                \n",
    "                self.player_history[player_id] = {\n",
    "                    'first_seen': self.stats['frames_processed'],\n",
    "                    'last_seen': self.stats['frames_processed'],\n",
    "                    'total_appearances': 1\n",
    "                }\n",
    "                \n",
    "                self.stats['new_players'] += 1\n",
    "                print(f\"➕ New player {player_id} initialized\")\n",
    "            return\n",
    "        \n",
    "        # Prepare all players (active + inactive) for matching\n",
    "        all_players = {**self.active_players, **self.inactive_players}\n",
    "        \n",
    "        if not all_players:\n",
    "            # Create new players\n",
    "            for detection in detections:\n",
    "                player_id = self.next_player_id\n",
    "                self.next_player_id += 1\n",
    "                \n",
    "                self.active_players[player_id] = {\n",
    "                    'bbox': detection['bbox'],\n",
    "                    'center': detection['center'],\n",
    "                    'features': deque([detection['features']], maxlen=self.feature_history_size),\n",
    "                    'confidence': detection['confidence'],\n",
    "                    'disappeared': 0,\n",
    "                    'last_seen_frame': self.stats['frames_processed'],\n",
    "                    'total_detections': 1\n",
    "                }\n",
    "                \n",
    "                self.stats['new_players'] += 1\n",
    "            return\n",
    "        \n",
    "        # Create similarity matrix\n",
    "        player_ids = list(all_players.keys())\n",
    "        similarity_matrix = np.zeros((len(detections), len(player_ids)))\n",
    "        \n",
    "        for i, detection in enumerate(detections):\n",
    "            for j, player_id in enumerate(player_ids):\n",
    "                player = all_players[player_id]\n",
    "                # Use most recent features\n",
    "                if len(player['features']) > 0:\n",
    "                    avg_features = np.mean(list(player['features']), axis=0)\n",
    "                    similarity, _, _ = self.calculate_similarity(\n",
    "                        detection['features'], avg_features, \n",
    "                        detection['center'], player['center']\n",
    "                    )\n",
    "                    similarity_matrix[i, j] = similarity\n",
    "        \n",
    "        # Greedy assignment - highest similarity first\n",
    "        used_detections = set()\n",
    "        used_players = set()\n",
    "        \n",
    "        # Create assignment candidates\n",
    "        assignments = []\n",
    "        for i in range(len(detections)):\n",
    "            for j in range(len(player_ids)):\n",
    "                if similarity_matrix[i, j] > 0.3:  # Minimum threshold\n",
    "                    assignments.append((similarity_matrix[i, j], i, j))\n",
    "        \n",
    "        assignments.sort(reverse=True)\n",
    "        \n",
    "        # Assign detections to players\n",
    "        for similarity, det_idx, player_idx in assignments:\n",
    "            if det_idx in used_detections or player_idx in used_players:\n",
    "                continue\n",
    "            \n",
    "            player_id = player_ids[player_idx]\n",
    "            detection = detections[det_idx]\n",
    "            \n",
    "            if similarity > self.reid_similarity_threshold:\n",
    "                # Successful match\n",
    "                if player_id in self.inactive_players:\n",
    "                    # Re-identification!\n",
    "                    self.active_players[player_id] = self.inactive_players[player_id]\n",
    "                    del self.inactive_players[player_id]\n",
    "                    self.stats['reidentifications'] += 1\n",
    "                    print(f\"🔄 RE-IDENTIFIED Player {player_id} (similarity: {similarity:.3f})\")\n",
    "                \n",
    "                # Update player\n",
    "                self.active_players[player_id]['bbox'] = detection['bbox']\n",
    "                self.active_players[player_id]['center'] = detection['center']\n",
    "                self.active_players[player_id]['features'].append(detection['features'])\n",
    "                self.active_players[player_id]['confidence'] = detection['confidence']\n",
    "                self.active_players[player_id]['disappeared'] = 0\n",
    "                self.active_players[player_id]['last_seen_frame'] = self.stats['frames_processed']\n",
    "                self.active_players[player_id]['total_detections'] += 1\n",
    "                \n",
    "                # Update history\n",
    "                if player_id in self.player_history:\n",
    "                    self.player_history[player_id]['last_seen'] = self.stats['frames_processed']\n",
    "                    self.player_history[player_id]['total_appearances'] += 1\n",
    "                \n",
    "                used_detections.add(det_idx)\n",
    "                used_players.add(player_idx)\n",
    "        \n",
    "        # Create new players for unmatched detections\n",
    "        for i, detection in enumerate(detections):\n",
    "            if i not in used_detections:\n",
    "                player_id = self.next_player_id\n",
    "                self.next_player_id += 1\n",
    "                \n",
    "                self.active_players[player_id] = {\n",
    "                    'bbox': detection['bbox'],\n",
    "                    'center': detection['center'],\n",
    "                    'features': deque([detection['features']], maxlen=self.feature_history_size),\n",
    "                    'confidence': detection['confidence'],\n",
    "                    'disappeared': 0,\n",
    "                    'last_seen_frame': self.stats['frames_processed'],\n",
    "                    'total_detections': 1\n",
    "                }\n",
    "                \n",
    "                self.player_history[player_id] = {\n",
    "                    'first_seen': self.stats['frames_processed'],\n",
    "                    'last_seen': self.stats['frames_processed'],\n",
    "                    'total_appearances': 1\n",
    "                }\n",
    "                \n",
    "                self.stats['new_players'] += 1\n",
    "                print(f\"➕ New player {player_id} detected\")\n",
    "        \n",
    "        # Handle unmatched active players\n",
    "        for j, player_id in enumerate(player_ids):\n",
    "            if j not in used_players and player_id in self.active_players:\n",
    "                self.active_players[player_id]['disappeared'] += 1\n",
    "                \n",
    "                if self.active_players[player_id]['disappeared'] > self.max_disappeared:\n",
    "                    # Move to inactive\n",
    "                    self.inactive_players[player_id] = self.active_players[player_id]\n",
    "                    self.inactive_players[player_id]['inactive_time'] = 0\n",
    "                    del self.active_players[player_id]\n",
    "                    print(f\"💤 Player {player_id} moved to inactive\")\n",
    "        \n",
    "        # Clean up old inactive players\n",
    "        to_remove = []\n",
    "        for player_id, player in self.inactive_players.items():\n",
    "            player['inactive_time'] += 1\n",
    "            if player['inactive_time'] > self.max_inactive_time:\n",
    "                to_remove.append(player_id)\n",
    "        \n",
    "        for player_id in to_remove:\n",
    "            del self.inactive_players[player_id]\n",
    "            print(f\"🗑️ Removed player {player_id} from tracking\")\n",
    "    \n",
    "    def draw_enhanced_detections(self, frame):\n",
    "        \"\"\"Draw enhanced bounding boxes with LARGE VISIBLE IDs\"\"\"\n",
    "        output_frame = frame.copy()\n",
    "        \n",
    "        # Draw active players with LARGE, VISIBLE IDs\n",
    "        for player_id, player in self.active_players.items():\n",
    "            x1, y1, x2, y2 = map(int, player['bbox'])\n",
    "            \n",
    "            # Choose color\n",
    "            color_idx = (player_id - 1) % len(self.colors)\n",
    "            color = self.colors[color_idx]\n",
    "            \n",
    "            # Draw thick bounding box\n",
    "            cv2.rectangle(output_frame, (x1, y1), (x2, y2), color, 4)\n",
    "            \n",
    "            # LARGE PLAYER ID - Multiple locations for visibility\n",
    "            player_text = f\"ID:{player_id}\"\n",
    "            \n",
    "            # Large font settings\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 1.2\n",
    "            thickness = 3\n",
    "            \n",
    "            # Get text size\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(player_text, font, font_scale, thickness)\n",
    "            \n",
    "            # Draw ID above bounding box with background\n",
    "            cv2.rectangle(output_frame, \n",
    "                         (x1, y1 - text_height - 15), \n",
    "                         (x1 + text_width + 10, y1), \n",
    "                         color, -1)\n",
    "            cv2.putText(output_frame, player_text, (x1 + 5, y1 - 8), \n",
    "                       font, font_scale, (255, 255, 255), thickness)\n",
    "            \n",
    "            # Draw ID inside bounding box (center)\n",
    "            center_x = (x1 + x2) // 2\n",
    "            center_y = (y1 + y2) // 2\n",
    "            \n",
    "            # Background circle for center ID\n",
    "            cv2.circle(output_frame, (center_x, center_y), 25, color, -1)\n",
    "            cv2.circle(output_frame, (center_x, center_y), 25, (255, 255, 255), 3)\n",
    "            \n",
    "            # Center ID text\n",
    "            id_text = str(player_id)\n",
    "            (id_width, id_height), _ = cv2.getTextSize(id_text, font, 0.8, 2)\n",
    "            cv2.putText(output_frame, id_text, \n",
    "                       (center_x - id_width//2, center_y + id_height//2), \n",
    "                       font, 0.8, (255, 255, 255), 2)\n",
    "            \n",
    "            # Draw confidence and detection count\n",
    "            conf_text = f\"{player['confidence']:.2f}\"\n",
    "            cv2.putText(output_frame, conf_text, (x1, y2 + 25), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            \n",
    "            det_text = f\"#{player['total_detections']}\"\n",
    "            cv2.putText(output_frame, det_text, (x2 - 50, y1 - 8), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # Enhanced information overlay\n",
    "        info_y = 40\n",
    "        cv2.putText(output_frame, \"SINGLE FEED PLAYER RE-IDENTIFICATION\", (20, info_y), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4)\n",
    "        cv2.putText(output_frame, \"SINGLE FEED PLAYER RE-IDENTIFICATION\", (20, info_y), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "        \n",
    "        info_y += 50\n",
    "        cv2.putText(output_frame, f\"Active: {len(self.active_players)} | Inactive: {len(self.inactive_players)}\", \n",
    "                   (20, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        \n",
    "        info_y += 30\n",
    "        cv2.putText(output_frame, f\"Frame: {self.stats['frames_processed']} | Re-IDs: {self.stats['reidentifications']}\", \n",
    "                   (20, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        return output_frame\n",
    "    \n",
    "    def process_video(self, video_path, output_path):\n",
    "        \"\"\"Process video with Kaggle paths\"\"\"\n",
    "        print(f\"🎬 Opening video: {video_path}\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"❌ Error: Could not open video file!\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        print(f\"📊 Video: {width}x{height} @ {fps}fps ({total_frames} frames)\")\n",
    "        \n",
    "        # Create video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        print(\"🔄 Processing with enhanced re-identification...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Detect players\n",
    "            detections = self.detect_players(frame)\n",
    "            \n",
    "            # Update tracking\n",
    "            self.match_detections_to_players(detections, frame)\n",
    "            \n",
    "            # Draw with large visible IDs\n",
    "            output_frame = self.draw_enhanced_detections(frame)\n",
    "            \n",
    "            # Write frame\n",
    "            out.write(output_frame)\n",
    "            \n",
    "            self.stats['frames_processed'] += 1\n",
    "            \n",
    "            # Progress update\n",
    "            if self.stats['frames_processed'] % 30 == 0:\n",
    "                progress = (self.stats['frames_processed'] / total_frames) * 100\n",
    "                elapsed = time.time() - start_time\n",
    "                fps_actual = self.stats['frames_processed'] / elapsed\n",
    "                print(f\"📈 Progress: {self.stats['frames_processed']}/{total_frames} \"\n",
    "                      f\"({progress:.1f}%) - {fps_actual:.1f} fps\")\n",
    "        \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        print(f\"✅ Complete! Time: {processing_time:.1f}s\")\n",
    "        \n",
    "        # Print and save results\n",
    "        self.print_statistics()\n",
    "        self.save_results(output_path.replace('.mp4', '_results.json'))\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        \"\"\"Print tracking statistics\"\"\"\n",
    "        print(\"\\n📊 TRACKING STATISTICS\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"Frames processed: {self.stats['frames_processed']}\")\n",
    "        print(f\"Total detections: {self.stats['total_detections']}\")\n",
    "        print(f\"New players: {self.stats['new_players']}\")\n",
    "        print(f\"Re-identifications: {self.stats['reidentifications']}\")\n",
    "        print(f\"Active players: {len(self.active_players)}\")\n",
    "        print(f\"Inactive players: {len(self.inactive_players)}\")\n",
    "        print(f\"Total unique players: {len(self.player_history)}\")\n",
    "        \n",
    "        if self.stats['reidentifications'] > 0:\n",
    "            print(\"✅ RE-IDENTIFICATION WORKING!\")\n",
    "        \n",
    "        if self.player_history:\n",
    "            print(\"\\n👥 PLAYER DETAILS\")\n",
    "            for pid, history in self.player_history.items():\n",
    "                status = \"ACTIVE\" if pid in self.active_players else \"INACTIVE\"\n",
    "                print(f\"Player {pid}: {history['total_appearances']} appearances [{status}]\")\n",
    "    \n",
    "    def save_results(self, results_path):\n",
    "        \"\"\"Save results to JSON\"\"\"\n",
    "        results = {\n",
    "            'statistics': self.stats,\n",
    "            'player_history': self.player_history,\n",
    "            'active_players': len(self.active_players),\n",
    "            'inactive_players': len(self.inactive_players),\n",
    "            'total_unique_players': len(self.player_history),\n",
    "            'reidentification_success': self.stats['reidentifications'] > 0\n",
    "        }\n",
    "        \n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        print(f\"📋 Results saved: {results_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for Kaggle environment\"\"\"\n",
    "    print(\"🚀 Single Feed Player Re-Identification System (Kaggle)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Kaggle paths\n",
    "    model_path = \"/kaggle/input/yolov11/pytorch/default/1/best.pt\"\n",
    "    input_video = \"/kaggle/input/play-videos/15sec_input_720p.mp4\"\n",
    "    output_video = \"/kaggle/working/15sec_output_reidentified_720p.mp4\"\n",
    "    \n",
    "    # Check paths\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"❌ Model not found: {model_path}\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(input_video):\n",
    "        print(f\"❌ Video not found: {input_video}\")\n",
    "        return\n",
    "    \n",
    "    print(\"✅ All files found!\")\n",
    "    \n",
    "    # Initialize system\n",
    "    reid_system = SingleFeedPlayerReID(model_path)\n",
    "    \n",
    "    # Process video\n",
    "    reid_system.process_video(input_video, output_video)\n",
    "    \n",
    "    print(\"\\n🎉 KAGGLE RE-IDENTIFICATION COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"📂 Output: {output_video}\")\n",
    "    print(f\"📊 Results: {output_video.replace('.mp4', '_results.json')}\")\n",
    "    print(\"\\n✨ Features:\")\n",
    "    print(\"   • LARGE VISIBLE Player IDs\")\n",
    "    print(\"   • Enhanced re-identification\")\n",
    "    print(\"   • Kaggle-optimized paths\")\n",
    "    print(\"   • Real-time processing\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7743693,
     "sourceId": 12287184,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 386742,
     "modelInstanceId": 365850,
     "sourceId": 450953,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 219.758759,
   "end_time": "2025-06-30T04:15:36.389118",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-30T04:11:56.630359",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
