{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2557df68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T04:12:03.154553Z",
     "iopub.status.busy": "2025-06-30T04:12:03.154337Z",
     "iopub.status.idle": "2025-06-30T04:14:53.827297Z",
     "shell.execute_reply": "2025-06-30T04:14:53.826431Z"
    },
    "papermill": {
     "duration": 170.6774,
     "end_time": "2025-06-30T04:14:53.828737",
     "exception": false,
     "start_time": "2025-06-30T04:12:03.151337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics==8.0.196\r\n",
      "  Downloading ultralytics-8.0.196-py3-none-any.whl.metadata (31 kB)\r\n",
      "Collecting opencv-python==4.8.1.78\r\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\r\n",
      "Collecting numpy==1.24.3\r\n",
      "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\r\n",
      "Collecting scipy==1.11.3\r\n",
      "  Downloading scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting scikit-learn==1.3.0\r\n",
      "  Downloading scikit_learn-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting torch==2.0.1\r\n",
      "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\r\n",
      "Collecting torchvision==0.15.2\r\n",
      "  Downloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (3.7.2)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (11.1.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (4.67.1)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (2.2.3)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (0.12.2)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (7.0.0)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.0.196) (9.0.0)\r\n",
      "Collecting thop>=0.1.1 (from ultralytics==8.0.196)\r\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.0) (1.5.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.0) (3.6.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.13.2)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\r\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.0.0 (from torch==2.0.1)\r\n",
      "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.2.0)\r\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\r\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\r\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.1)\r\n",
      "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (4.57.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (25.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.0.196) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.0.196) (2025.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (2025.4.26)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.0.196) (1.17.0)\r\n",
      "Downloading ultralytics-8.0.196-py3-none-any.whl (631 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_learn-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\r\n",
      "Downloading lit-18.1.8-py3-none-any.whl (96 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, scipy, opencv-python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, scikit-learn, triton, torch, torchvision, thop, ultralytics\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.15.2\r\n",
      "    Uninstalling scipy-1.15.2:\r\n",
      "      Successfully uninstalled scipy-1.15.2\r\n",
      "  Attempting uninstall: opencv-python\r\n",
      "    Found existing installation: opencv-python 4.11.0.86\r\n",
      "    Uninstalling opencv-python-4.11.0.86:\r\n",
      "      Successfully uninstalled opencv-python-4.11.0.86\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.2.0\r\n",
      "    Uninstalling triton-3.2.0:\r\n",
      "      Successfully uninstalled triton-3.2.0\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.6.0+cu124\r\n",
      "    Uninstalling torch-2.6.0+cu124:\r\n",
      "      Successfully uninstalled torch-2.6.0+cu124\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.21.0+cu124\r\n",
      "    Uninstalling torchvision-0.21.0+cu124:\r\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\r\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\r\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.3 which is incompatible.\r\n",
      "woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "pytorch-lightning 2.5.1.post0 requires torch>=2.1.0, but you have torch 2.0.1 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "bayesian-optimization 2.0.3 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\r\n",
      "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.11.3 which is incompatible.\r\n",
      "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\r\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.3.0 which is incompatible.\r\n",
      "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\r\n",
      "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\r\n",
      "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\r\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.3.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed lit-18.1.8 numpy-1.24.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 opencv-python-4.8.1.78 scikit-learn-1.3.0 scipy-1.11.3 thop-0.1.1.post2209072238 torch-2.0.1 torchvision-0.15.2 triton-2.0.0 ultralytics-8.0.196\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics==8.0.196 opencv-python==4.8.1.78 numpy==1.24.3 scipy==1.11.3 scikit-learn==1.3.0 torch==2.0.1 torchvision==0.15.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1a9d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T04:14:53.900387Z",
     "iopub.status.busy": "2025-06-30T04:14:53.900091Z",
     "iopub.status.idle": "2025-06-30T04:15:34.968852Z",
     "shell.execute_reply": "2025-06-30T04:15:34.967869Z"
    },
    "papermill": {
     "duration": 41.106584,
     "end_time": "2025-06-30T04:15:34.970427",
     "exception": false,
     "start_time": "2025-06-30T04:14:53.863843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Single Feed Player Re-Identification System (Kaggle)\n",
      "============================================================\n",
      "âœ… All files found!\n",
      "ğŸš€ Initializing Single Feed Player Re-Identification System (Kaggle)\n",
      "âœ… Loading model from: /kaggle/input/yolov11/pytorch/default/1/best.pt\n",
      "âœ… System initialized successfully!\n",
      "ğŸ¬ Opening video: /kaggle/input/play-videos/15sec_input_720p.mp4\n",
      "ğŸ“Š Video: 1280x720 @ 25fps (375 frames)\n",
      "ğŸ”„ Processing with enhanced re-identification...\n",
      "â• New player 1 initialized\n",
      "â• New player 2 initialized\n",
      "â• New player 3 initialized\n",
      "â• New player 4 initialized\n",
      "â• New player 5 initialized\n",
      "â• New player 6 initialized\n",
      "â• New player 7 initialized\n",
      "â• New player 8 initialized\n",
      "â• New player 9 initialized\n",
      "â• New player 10 initialized\n",
      "â• New player 11 initialized\n",
      "â• New player 12 initialized\n",
      "â• New player 13 initialized\n",
      "â• New player 14 initialized\n",
      "â• New player 15 initialized\n",
      "â• New player 16 initialized\n",
      "â• New player 17 initialized\n",
      "â• New player 18 initialized\n",
      "â• New player 19 initialized\n",
      "â• New player 20 detected\n",
      "â• New player 21 detected\n",
      "ğŸ“ˆ Progress: 30/375 (8.0%) - 3.9 fps\n",
      "â• New player 22 detected\n",
      "ğŸ“ˆ Progress: 60/375 (16.0%) - 6.1 fps\n",
      "ğŸ“ˆ Progress: 90/375 (24.0%) - 7.4 fps\n",
      "â• New player 23 detected\n",
      "ğŸ“ˆ Progress: 120/375 (32.0%) - 8.3 fps\n",
      "ğŸ’¤ Player 2 moved to inactive\n",
      "ğŸ’¤ Player 18 moved to inactive\n",
      "ğŸ“ˆ Progress: 150/375 (40.0%) - 9.0 fps\n",
      "ğŸ’¤ Player 14 moved to inactive\n",
      "ğŸ”„ RE-IDENTIFIED Player 14 (similarity: 0.899)\n",
      "ğŸ“ˆ Progress: 180/375 (48.0%) - 9.5 fps\n",
      "ğŸ”„ RE-IDENTIFIED Player 2 (similarity: 0.849)\n",
      "ğŸ’¤ Player 5 moved to inactive\n",
      "ğŸ”„ RE-IDENTIFIED Player 5 (similarity: 0.797)\n",
      "ğŸ’¤ Player 14 moved to inactive\n",
      "ğŸ’¤ Player 7 moved to inactive\n",
      "ğŸ“ˆ Progress: 210/375 (56.0%) - 10.0 fps\n",
      "ğŸ’¤ Player 1 moved to inactive\n",
      "ğŸ“ˆ Progress: 240/375 (64.0%) - 10.4 fps\n",
      "ğŸ’¤ Player 13 moved to inactive\n",
      "ğŸ’¤ Player 10 moved to inactive\n",
      "ğŸ’¤ Player 19 moved to inactive\n",
      "ğŸ”„ RE-IDENTIFIED Player 13 (similarity: 0.739)\n",
      "ğŸ”„ RE-IDENTIFIED Player 10 (similarity: 0.838)\n",
      "ğŸ’¤ Player 2 moved to inactive\n",
      "ğŸ’¤ Player 16 moved to inactive\n",
      "ğŸ—‘ï¸ Removed player 18 from tracking\n",
      "ğŸ“ˆ Progress: 270/375 (72.0%) - 10.7 fps\n",
      "ğŸ”„ RE-IDENTIFIED Player 16 (similarity: 0.932)\n",
      "ğŸ”„ RE-IDENTIFIED Player 19 (similarity: 0.975)\n",
      "ğŸ”„ RE-IDENTIFIED Player 2 (similarity: 0.867)\n",
      "ğŸ”„ RE-IDENTIFIED Player 1 (similarity: 0.850)\n",
      "ğŸ”„ RE-IDENTIFIED Player 7 (similarity: 0.771)\n",
      "ğŸ“ˆ Progress: 300/375 (80.0%) - 11.0 fps\n",
      "ğŸ—‘ï¸ Removed player 14 from tracking\n",
      "ğŸ“ˆ Progress: 330/375 (88.0%) - 11.2 fps\n",
      "ğŸ“ˆ Progress: 360/375 (96.0%) - 11.4 fps\n",
      "âœ… Complete! Time: 32.6s\n",
      "\n",
      "ğŸ“Š TRACKING STATISTICS\n",
      "========================================\n",
      "Frames processed: 375\n",
      "Total detections: 5577\n",
      "New players: 23\n",
      "Re-identifications: 10\n",
      "Active players: 21\n",
      "Inactive players: 0\n",
      "Total unique players: 23\n",
      "âœ… RE-IDENTIFICATION WORKING!\n",
      "\n",
      "ğŸ‘¥ PLAYER DETAILS\n",
      "Player 1: 237 appearances [ACTIVE]\n",
      "Player 2: 199 appearances [ACTIVE]\n",
      "Player 3: 324 appearances [ACTIVE]\n",
      "Player 4: 262 appearances [ACTIVE]\n",
      "Player 5: 265 appearances [ACTIVE]\n",
      "Player 6: 270 appearances [ACTIVE]\n",
      "Player 7: 228 appearances [ACTIVE]\n",
      "Player 8: 341 appearances [ACTIVE]\n",
      "Player 9: 256 appearances [ACTIVE]\n",
      "Player 10: 301 appearances [ACTIVE]\n",
      "Player 11: 237 appearances [ACTIVE]\n",
      "Player 12: 203 appearances [ACTIVE]\n",
      "Player 13: 280 appearances [ACTIVE]\n",
      "Player 14: 134 appearances [INACTIVE]\n",
      "Player 15: 264 appearances [ACTIVE]\n",
      "Player 16: 301 appearances [ACTIVE]\n",
      "Player 17: 176 appearances [ACTIVE]\n",
      "Player 18: 114 appearances [INACTIVE]\n",
      "Player 19: 273 appearances [ACTIVE]\n",
      "Player 20: 223 appearances [ACTIVE]\n",
      "Player 21: 254 appearances [ACTIVE]\n",
      "Player 22: 201 appearances [ACTIVE]\n",
      "Player 23: 234 appearances [ACTIVE]\n",
      "ğŸ“‹ Results saved: /kaggle/working/15sec_output_reidentified_720p_results.json\n",
      "\n",
      "ğŸ‰ KAGGLE RE-IDENTIFICATION COMPLETE!\n",
      "============================================================\n",
      "ğŸ“‚ Output: /kaggle/working/15sec_output_reidentified_720p.mp4\n",
      "ğŸ“Š Results: /kaggle/working/15sec_output_reidentified_720p_results.json\n",
      "\n",
      "âœ¨ Features:\n",
      "   â€¢ LARGE VISIBLE Player IDs\n",
      "   â€¢ Enhanced re-identification\n",
      "   â€¢ Kaggle-optimized paths\n",
      "   â€¢ Real-time processing\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import deque\n",
    "import json\n",
    "import time\n",
    "\n",
    "class SingleFeedPlayerReID:\n",
    "    def __init__(self, model_path=None):\n",
    "        \"\"\"Initialize the Single Feed Player Re-Identification system for Kaggle\"\"\"\n",
    "        print(\"ğŸš€ Initializing Single Feed Player Re-Identification System (Kaggle)\")\n",
    "        \n",
    "        # Kaggle model path\n",
    "        self.model_path = model_path or \"/kaggle/input/yolov11/pytorch/default/1/best.pt\"\n",
    "        \n",
    "        if not os.path.exists(self.model_path):\n",
    "            print(f\"âŒ Error: Model not found at {self.model_path}\")\n",
    "            print(\"Please ensure the YOLOv11 model is uploaded to Kaggle\")\n",
    "            return\n",
    "        \n",
    "        print(f\"âœ… Loading model from: {self.model_path}\")\n",
    "        self.model = YOLO(self.model_path)\n",
    "        \n",
    "        # Player tracking data\n",
    "        self.active_players = {}      # Currently visible players\n",
    "        self.inactive_players = {}    # Players who disappeared but might return\n",
    "        self.player_history = {}      # Complete history of all players\n",
    "        self.next_player_id = 1\n",
    "        \n",
    "        # Enhanced tracking parameters for better re-identification\n",
    "        self.max_disappeared = 30     # Reduced frames before moving to inactive\n",
    "        self.max_inactive_time = 120  # Frames to keep inactive players for re-identification\n",
    "        self.feature_history_size = 10 # Number of feature vectors to store\n",
    "        self.confidence_threshold = 0.25 # Lower threshold for better detection\n",
    "        \n",
    "        # Re-identification parameters - more lenient for better matching\n",
    "        self.reid_similarity_threshold = 0.65  # Lower threshold for easier re-identification\n",
    "        self.spatial_weight = 0.4     # Increased spatial weight\n",
    "        self.feature_weight = 0.6     # Reduced feature weight for more flexibility\n",
    "        \n",
    "        # Enhanced color palette for player visualization\n",
    "        self.colors = [\n",
    "            (0, 0, 255),     # Red\n",
    "            (0, 255, 0),     # Green  \n",
    "            (255, 0, 0),     # Blue\n",
    "            (0, 255, 255),   # Yellow\n",
    "            (255, 0, 255),   # Magenta\n",
    "            (255, 255, 0),   # Cyan\n",
    "            (128, 0, 128),   # Purple\n",
    "            (255, 165, 0),   # Orange\n",
    "            (0, 128, 0),     # Dark Green\n",
    "            (128, 128, 0),   # Olive\n",
    "            (0, 0, 128),     # Navy\n",
    "            (128, 0, 0),     # Maroon\n",
    "            (255, 192, 203), # Pink\n",
    "            (165, 42, 42),   # Brown\n",
    "            (64, 224, 208),  # Turquoise\n",
    "            (255, 20, 147),  # Deep Pink\n",
    "            (0, 191, 255),   # Deep Sky Blue\n",
    "            (50, 205, 50),   # Lime Green\n",
    "            (255, 69, 0),    # Red Orange\n",
    "            (138, 43, 226),  # Blue Violet\n",
    "        ]\n",
    "        \n",
    "        # Statistics tracking\n",
    "        self.stats = {\n",
    "            'total_detections': 0,\n",
    "            'reidentifications': 0,\n",
    "            'new_players': 0,\n",
    "            'frames_processed': 0\n",
    "        }\n",
    "        \n",
    "        print(\"âœ… System initialized successfully!\")\n",
    "    \n",
    "    def extract_enhanced_features(self, frame, bbox):\n",
    "        \"\"\"Extract comprehensive visual features from player bounding box\"\"\"\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        \n",
    "        # Ensure coordinates are within frame bounds\n",
    "        h, w = frame.shape[:2]\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w, x2), min(h, y2)\n",
    "        \n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return np.zeros(128)  # Reduced feature size for efficiency\n",
    "        \n",
    "        # Extract player region\n",
    "        player_region = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        if player_region.size == 0:\n",
    "            return np.zeros(128)\n",
    "        \n",
    "        # Resize to standard size for consistent feature extraction\n",
    "        try:\n",
    "            player_region = cv2.resize(player_region, (32, 64))  # Smaller for efficiency\n",
    "        except:\n",
    "            return np.zeros(128)\n",
    "        \n",
    "        # 1. Color Features - RGB histograms\n",
    "        hist_b = cv2.calcHist([player_region], [0], None, [16], [0, 256])\n",
    "        hist_g = cv2.calcHist([player_region], [1], None, [16], [0, 256])\n",
    "        hist_r = cv2.calcHist([player_region], [2], None, [16], [0, 256])\n",
    "        \n",
    "        # Normalize histograms\n",
    "        hist_b = hist_b.flatten() / (hist_b.sum() + 1e-7)\n",
    "        hist_g = hist_g.flatten() / (hist_g.sum() + 1e-7)\n",
    "        hist_r = hist_r.flatten() / (hist_r.sum() + 1e-7)\n",
    "        \n",
    "        # 2. HSV color space for better color representation\n",
    "        try:\n",
    "            hsv_region = cv2.cvtColor(player_region, cv2.COLOR_BGR2HSV)\n",
    "            hist_h = cv2.calcHist([hsv_region], [0], None, [16], [0, 180])\n",
    "            hist_s = cv2.calcHist([hsv_region], [1], None, [16], [0, 256])\n",
    "            hist_v = cv2.calcHist([hsv_region], [2], None, [16], [0, 256])\n",
    "            \n",
    "            hist_h = hist_h.flatten() / (hist_h.sum() + 1e-7)\n",
    "            hist_s = hist_s.flatten() / (hist_s.sum() + 1e-7)\n",
    "            hist_v = hist_v.flatten() / (hist_v.sum() + 1e-7)\n",
    "        except:\n",
    "            hist_h = np.zeros(16)\n",
    "            hist_s = np.zeros(16)\n",
    "            hist_v = np.zeros(16)\n",
    "        \n",
    "        # 3. Simple texture features\n",
    "        try:\n",
    "            gray = cv2.cvtColor(player_region, cv2.COLOR_BGR2GRAY)\n",
    "            texture_features = [\n",
    "                np.std(gray),           # Standard deviation\n",
    "                np.mean(gray),          # Mean intensity\n",
    "                np.max(gray) - np.min(gray) if gray.size > 0 else 0,  # Range\n",
    "            ]\n",
    "            texture_features = np.array(texture_features[:16])  # Limit size\n",
    "            if len(texture_features) < 16:\n",
    "                texture_features = np.pad(texture_features, (0, 16-len(texture_features)))\n",
    "        except:\n",
    "            texture_features = np.zeros(16)\n",
    "        \n",
    "        # 4. Geometric features\n",
    "        aspect_ratio = (x2 - x1) / max(y2 - y1, 1)\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "        geometric_features = np.array([aspect_ratio, area / 10000.0])\n",
    "        \n",
    "        # Combine all features (16+16+16+16+16+16+16+2 = 128 features)\n",
    "        features = np.concatenate([\n",
    "            hist_b, hist_g, hist_r,  # RGB: 48 features\n",
    "            hist_h, hist_s, hist_v,  # HSV: 48 features\n",
    "            texture_features,        # Texture: 16 features\n",
    "            geometric_features       # Geometric: 2 features\n",
    "        ])\n",
    "        \n",
    "        # Ensure fixed size\n",
    "        if len(features) < 128:\n",
    "            features = np.pad(features, (0, 128-len(features)))\n",
    "        \n",
    "        return features[:128]\n",
    "    \n",
    "    def detect_players(self, frame):\n",
    "        \"\"\"Detect players in a frame using YOLO\"\"\"\n",
    "        try:\n",
    "            results = self.model(frame, verbose=False, conf=self.confidence_threshold)\n",
    "            detections = []\n",
    "            \n",
    "            for result in results:\n",
    "                boxes = result.boxes\n",
    "                if boxes is not None:\n",
    "                    for box in boxes:\n",
    "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                        confidence = box.conf[0].cpu().numpy()\n",
    "                        class_id = int(box.cls[0].cpu().numpy())\n",
    "                        \n",
    "                        # Filter for person detections (class 0 in COCO/YOLO)\n",
    "                        if confidence > self.confidence_threshold:\n",
    "                            width = x2 - x1\n",
    "                            height = y2 - y1\n",
    "                            aspect_ratio = width / max(height, 1)\n",
    "                            \n",
    "                            # Filter realistic human detections\n",
    "                            if (width > 5 and height > 10 and \n",
    "                                aspect_ratio > 0.2 and aspect_ratio < 3.0):\n",
    "                                \n",
    "                                detections.append({\n",
    "                                    'bbox': [x1, y1, x2, y2],\n",
    "                                    'confidence': confidence,\n",
    "                                    'center': [(x1 + x2) / 2, (y1 + y2) / 2],\n",
    "                                    'area': width * height\n",
    "                                })\n",
    "            \n",
    "            # Sort by confidence\n",
    "            detections.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "            self.stats['total_detections'] += len(detections)\n",
    "            \n",
    "            return detections\n",
    "        except Exception as e:\n",
    "            print(f\"Detection error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def calculate_similarity(self, features1, features2, center1, center2):\n",
    "        \"\"\"Calculate similarity between two player detections\"\"\"\n",
    "        try:\n",
    "            # Feature similarity (cosine similarity)\n",
    "            dot_product = np.dot(features1, features2)\n",
    "            norm1 = np.linalg.norm(features1)\n",
    "            norm2 = np.linalg.norm(features2)\n",
    "            \n",
    "            if norm1 == 0 or norm2 == 0:\n",
    "                feature_sim = 0\n",
    "            else:\n",
    "                feature_sim = dot_product / (norm1 * norm2)\n",
    "                feature_sim = max(0, feature_sim)  # Ensure non-negative\n",
    "            \n",
    "            # Spatial similarity\n",
    "            spatial_dist = np.linalg.norm(np.array(center1) - np.array(center2))\n",
    "            spatial_sim = 1 / (1 + spatial_dist / 200.0)  # Normalized spatial similarity\n",
    "            \n",
    "            # Combined similarity\n",
    "            combined_sim = (self.feature_weight * feature_sim + \n",
    "                           self.spatial_weight * spatial_sim)\n",
    "            \n",
    "            return combined_sim, feature_sim, spatial_sim\n",
    "        except:\n",
    "            return 0.0, 0.0, 0.0\n",
    "    \n",
    "    def match_detections_to_players(self, detections, frame):\n",
    "        \"\"\"Match detections to existing players with improved re-identification\"\"\"\n",
    "        if not detections:\n",
    "            # Handle disappeared players\n",
    "            for player_id in list(self.active_players.keys()):\n",
    "                self.active_players[player_id]['disappeared'] += 1\n",
    "                if self.active_players[player_id]['disappeared'] > self.max_disappeared:\n",
    "                    # Move to inactive\n",
    "                    self.inactive_players[player_id] = self.active_players[player_id]\n",
    "                    self.inactive_players[player_id]['inactive_time'] = 0\n",
    "                    del self.active_players[player_id]\n",
    "                    print(f\"ğŸ’¤ Player {player_id} moved to inactive pool\")\n",
    "            return\n",
    "        \n",
    "        # Extract features for all detections\n",
    "        for detection in detections:\n",
    "            detection['features'] = self.extract_enhanced_features(frame, detection['bbox'])\n",
    "        \n",
    "        # Initialize first players\n",
    "        if not self.active_players and not self.inactive_players:\n",
    "            for detection in detections:\n",
    "                player_id = self.next_player_id\n",
    "                self.next_player_id += 1\n",
    "                \n",
    "                self.active_players[player_id] = {\n",
    "                    'bbox': detection['bbox'],\n",
    "                    'center': detection['center'],\n",
    "                    'features': deque([detection['features']], maxlen=self.feature_history_size),\n",
    "                    'confidence': detection['confidence'],\n",
    "                    'disappeared': 0,\n",
    "                    'last_seen_frame': self.stats['frames_processed'],\n",
    "                    'total_detections': 1\n",
    "                }\n",
    "                \n",
    "                self.player_history[player_id] = {\n",
    "                    'first_seen': self.stats['frames_processed'],\n",
    "                    'last_seen': self.stats['frames_processed'],\n",
    "                    'total_appearances': 1\n",
    "                }\n",
    "                \n",
    "                self.stats['new_players'] += 1\n",
    "                print(f\"â• New player {player_id} initialized\")\n",
    "            return\n",
    "        \n",
    "        # Prepare all players (active + inactive) for matching\n",
    "        all_players = {**self.active_players, **self.inactive_players}\n",
    "        \n",
    "        if not all_players:\n",
    "            # Create new players\n",
    "            for detection in detections:\n",
    "                player_id = self.next_player_id\n",
    "                self.next_player_id += 1\n",
    "                \n",
    "                self.active_players[player_id] = {\n",
    "                    'bbox': detection['bbox'],\n",
    "                    'center': detection['center'],\n",
    "                    'features': deque([detection['features']], maxlen=self.feature_history_size),\n",
    "                    'confidence': detection['confidence'],\n",
    "                    'disappeared': 0,\n",
    "                    'last_seen_frame': self.stats['frames_processed'],\n",
    "                    'total_detections': 1\n",
    "                }\n",
    "                \n",
    "                self.stats['new_players'] += 1\n",
    "            return\n",
    "        \n",
    "        # Create similarity matrix\n",
    "        player_ids = list(all_players.keys())\n",
    "        similarity_matrix = np.zeros((len(detections), len(player_ids)))\n",
    "        \n",
    "        for i, detection in enumerate(detections):\n",
    "            for j, player_id in enumerate(player_ids):\n",
    "                player = all_players[player_id]\n",
    "                # Use most recent features\n",
    "                if len(player['features']) > 0:\n",
    "                    avg_features = np.mean(list(player['features']), axis=0)\n",
    "                    similarity, _, _ = self.calculate_similarity(\n",
    "                        detection['features'], avg_features, \n",
    "                        detection['center'], player['center']\n",
    "                    )\n",
    "                    similarity_matrix[i, j] = similarity\n",
    "        \n",
    "        # Greedy assignment - highest similarity first\n",
    "        used_detections = set()\n",
    "        used_players = set()\n",
    "        \n",
    "        # Create assignment candidates\n",
    "        assignments = []\n",
    "        for i in range(len(detections)):\n",
    "            for j in range(len(player_ids)):\n",
    "                if similarity_matrix[i, j] > 0.3:  # Minimum threshold\n",
    "                    assignments.append((similarity_matrix[i, j], i, j))\n",
    "        \n",
    "        assignments.sort(reverse=True)\n",
    "        \n",
    "        # Assign detections to players\n",
    "        for similarity, det_idx, player_idx in assignments:\n",
    "            if det_idx in used_detections or player_idx in used_players:\n",
    "                continue\n",
    "            \n",
    "            player_id = player_ids[player_idx]\n",
    "            detection = detections[det_idx]\n",
    "            \n",
    "            if similarity > self.reid_similarity_threshold:\n",
    "                # Successful match\n",
    "                if player_id in self.inactive_players:\n",
    "                    # Re-identification!\n",
    "                    self.active_players[player_id] = self.inactive_players[player_id]\n",
    "                    del self.inactive_players[player_id]\n",
    "                    self.stats['reidentifications'] += 1\n",
    "                    print(f\"ğŸ”„ RE-IDENTIFIED Player {player_id} (similarity: {similarity:.3f})\")\n",
    "                \n",
    "                # Update player\n",
    "                self.active_players[player_id]['bbox'] = detection['bbox']\n",
    "                self.active_players[player_id]['center'] = detection['center']\n",
    "                self.active_players[player_id]['features'].append(detection['features'])\n",
    "                self.active_players[player_id]['confidence'] = detection['confidence']\n",
    "                self.active_players[player_id]['disappeared'] = 0\n",
    "                self.active_players[player_id]['last_seen_frame'] = self.stats['frames_processed']\n",
    "                self.active_players[player_id]['total_detections'] += 1\n",
    "                \n",
    "                # Update history\n",
    "                if player_id in self.player_history:\n",
    "                    self.player_history[player_id]['last_seen'] = self.stats['frames_processed']\n",
    "                    self.player_history[player_id]['total_appearances'] += 1\n",
    "                \n",
    "                used_detections.add(det_idx)\n",
    "                used_players.add(player_idx)\n",
    "        \n",
    "        # Create new players for unmatched detections\n",
    "        for i, detection in enumerate(detections):\n",
    "            if i not in used_detections:\n",
    "                player_id = self.next_player_id\n",
    "                self.next_player_id += 1\n",
    "                \n",
    "                self.active_players[player_id] = {\n",
    "                    'bbox': detection['bbox'],\n",
    "                    'center': detection['center'],\n",
    "                    'features': deque([detection['features']], maxlen=self.feature_history_size),\n",
    "                    'confidence': detection['confidence'],\n",
    "                    'disappeared': 0,\n",
    "                    'last_seen_frame': self.stats['frames_processed'],\n",
    "                    'total_detections': 1\n",
    "                }\n",
    "                \n",
    "                self.player_history[player_id] = {\n",
    "                    'first_seen': self.stats['frames_processed'],\n",
    "                    'last_seen': self.stats['frames_processed'],\n",
    "                    'total_appearances': 1\n",
    "                }\n",
    "                \n",
    "                self.stats['new_players'] += 1\n",
    "                print(f\"â• New player {player_id} detected\")\n",
    "        \n",
    "        # Handle unmatched active players\n",
    "        for j, player_id in enumerate(player_ids):\n",
    "            if j not in used_players and player_id in self.active_players:\n",
    "                self.active_players[player_id]['disappeared'] += 1\n",
    "                \n",
    "                if self.active_players[player_id]['disappeared'] > self.max_disappeared:\n",
    "                    # Move to inactive\n",
    "                    self.inactive_players[player_id] = self.active_players[player_id]\n",
    "                    self.inactive_players[player_id]['inactive_time'] = 0\n",
    "                    del self.active_players[player_id]\n",
    "                    print(f\"ğŸ’¤ Player {player_id} moved to inactive\")\n",
    "        \n",
    "        # Clean up old inactive players\n",
    "        to_remove = []\n",
    "        for player_id, player in self.inactive_players.items():\n",
    "            player['inactive_time'] += 1\n",
    "            if player['inactive_time'] > self.max_inactive_time:\n",
    "                to_remove.append(player_id)\n",
    "        \n",
    "        for player_id in to_remove:\n",
    "            del self.inactive_players[player_id]\n",
    "            print(f\"ğŸ—‘ï¸ Removed player {player_id} from tracking\")\n",
    "    \n",
    "    def draw_enhanced_detections(self, frame):\n",
    "        \"\"\"Draw enhanced bounding boxes with LARGE VISIBLE IDs\"\"\"\n",
    "        output_frame = frame.copy()\n",
    "        \n",
    "        # Draw active players with LARGE, VISIBLE IDs\n",
    "        for player_id, player in self.active_players.items():\n",
    "            x1, y1, x2, y2 = map(int, player['bbox'])\n",
    "            \n",
    "            # Choose color\n",
    "            color_idx = (player_id - 1) % len(self.colors)\n",
    "            color = self.colors[color_idx]\n",
    "            \n",
    "            # Draw thick bounding box\n",
    "            cv2.rectangle(output_frame, (x1, y1), (x2, y2), color, 4)\n",
    "            \n",
    "            # LARGE PLAYER ID - Multiple locations for visibility\n",
    "            player_text = f\"ID:{player_id}\"\n",
    "            \n",
    "            # Large font settings\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 1.2\n",
    "            thickness = 3\n",
    "            \n",
    "            # Get text size\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(player_text, font, font_scale, thickness)\n",
    "            \n",
    "            # Draw ID above bounding box with background\n",
    "            cv2.rectangle(output_frame, \n",
    "                         (x1, y1 - text_height - 15), \n",
    "                         (x1 + text_width + 10, y1), \n",
    "                         color, -1)\n",
    "            cv2.putText(output_frame, player_text, (x1 + 5, y1 - 8), \n",
    "                       font, font_scale, (255, 255, 255), thickness)\n",
    "            \n",
    "            # Draw ID inside bounding box (center)\n",
    "            center_x = (x1 + x2) // 2\n",
    "            center_y = (y1 + y2) // 2\n",
    "            \n",
    "            # Background circle for center ID\n",
    "            cv2.circle(output_frame, (center_x, center_y), 25, color, -1)\n",
    "            cv2.circle(output_frame, (center_x, center_y), 25, (255, 255, 255), 3)\n",
    "            \n",
    "            # Center ID text\n",
    "            id_text = str(player_id)\n",
    "            (id_width, id_height), _ = cv2.getTextSize(id_text, font, 0.8, 2)\n",
    "            cv2.putText(output_frame, id_text, \n",
    "                       (center_x - id_width//2, center_y + id_height//2), \n",
    "                       font, 0.8, (255, 255, 255), 2)\n",
    "            \n",
    "            # Draw confidence and detection count\n",
    "            conf_text = f\"{player['confidence']:.2f}\"\n",
    "            cv2.putText(output_frame, conf_text, (x1, y2 + 25), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            \n",
    "            det_text = f\"#{player['total_detections']}\"\n",
    "            cv2.putText(output_frame, det_text, (x2 - 50, y1 - 8), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # Enhanced information overlay\n",
    "        info_y = 40\n",
    "        cv2.putText(output_frame, \"SINGLE FEED PLAYER RE-IDENTIFICATION\", (20, info_y), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4)\n",
    "        cv2.putText(output_frame, \"SINGLE FEED PLAYER RE-IDENTIFICATION\", (20, info_y), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "        \n",
    "        info_y += 50\n",
    "        cv2.putText(output_frame, f\"Active: {len(self.active_players)} | Inactive: {len(self.inactive_players)}\", \n",
    "                   (20, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        \n",
    "        info_y += 30\n",
    "        cv2.putText(output_frame, f\"Frame: {self.stats['frames_processed']} | Re-IDs: {self.stats['reidentifications']}\", \n",
    "                   (20, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        return output_frame\n",
    "    \n",
    "    def process_video(self, video_path, output_path):\n",
    "        \"\"\"Process video with Kaggle paths\"\"\"\n",
    "        print(f\"ğŸ¬ Opening video: {video_path}\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"âŒ Error: Could not open video file!\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        print(f\"ğŸ“Š Video: {width}x{height} @ {fps}fps ({total_frames} frames)\")\n",
    "        \n",
    "        # Create video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        print(\"ğŸ”„ Processing with enhanced re-identification...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Detect players\n",
    "            detections = self.detect_players(frame)\n",
    "            \n",
    "            # Update tracking\n",
    "            self.match_detections_to_players(detections, frame)\n",
    "            \n",
    "            # Draw with large visible IDs\n",
    "            output_frame = self.draw_enhanced_detections(frame)\n",
    "            \n",
    "            # Write frame\n",
    "            out.write(output_frame)\n",
    "            \n",
    "            self.stats['frames_processed'] += 1\n",
    "            \n",
    "            # Progress update\n",
    "            if self.stats['frames_processed'] % 30 == 0:\n",
    "                progress = (self.stats['frames_processed'] / total_frames) * 100\n",
    "                elapsed = time.time() - start_time\n",
    "                fps_actual = self.stats['frames_processed'] / elapsed\n",
    "                print(f\"ğŸ“ˆ Progress: {self.stats['frames_processed']}/{total_frames} \"\n",
    "                      f\"({progress:.1f}%) - {fps_actual:.1f} fps\")\n",
    "        \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        print(f\"âœ… Complete! Time: {processing_time:.1f}s\")\n",
    "        \n",
    "        # Print and save results\n",
    "        self.print_statistics()\n",
    "        self.save_results(output_path.replace('.mp4', '_results.json'))\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        \"\"\"Print tracking statistics\"\"\"\n",
    "        print(\"\\nğŸ“Š TRACKING STATISTICS\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"Frames processed: {self.stats['frames_processed']}\")\n",
    "        print(f\"Total detections: {self.stats['total_detections']}\")\n",
    "        print(f\"New players: {self.stats['new_players']}\")\n",
    "        print(f\"Re-identifications: {self.stats['reidentifications']}\")\n",
    "        print(f\"Active players: {len(self.active_players)}\")\n",
    "        print(f\"Inactive players: {len(self.inactive_players)}\")\n",
    "        print(f\"Total unique players: {len(self.player_history)}\")\n",
    "        \n",
    "        if self.stats['reidentifications'] > 0:\n",
    "            print(\"âœ… RE-IDENTIFICATION WORKING!\")\n",
    "        \n",
    "        if self.player_history:\n",
    "            print(\"\\nğŸ‘¥ PLAYER DETAILS\")\n",
    "            for pid, history in self.player_history.items():\n",
    "                status = \"ACTIVE\" if pid in self.active_players else \"INACTIVE\"\n",
    "                print(f\"Player {pid}: {history['total_appearances']} appearances [{status}]\")\n",
    "    \n",
    "    def save_results(self, results_path):\n",
    "        \"\"\"Save results to JSON\"\"\"\n",
    "        results = {\n",
    "            'statistics': self.stats,\n",
    "            'player_history': self.player_history,\n",
    "            'active_players': len(self.active_players),\n",
    "            'inactive_players': len(self.inactive_players),\n",
    "            'total_unique_players': len(self.player_history),\n",
    "            'reidentification_success': self.stats['reidentifications'] > 0\n",
    "        }\n",
    "        \n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        print(f\"ğŸ“‹ Results saved: {results_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for Kaggle environment\"\"\"\n",
    "    print(\"ğŸš€ Single Feed Player Re-Identification System (Kaggle)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Kaggle paths\n",
    "    model_path = \"/kaggle/input/yolov11/pytorch/default/1/best.pt\"\n",
    "    input_video = \"/kaggle/input/play-videos/15sec_input_720p.mp4\"\n",
    "    output_video = \"/kaggle/working/15sec_output_reidentified_720p.mp4\"\n",
    "    \n",
    "    # Check paths\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âŒ Model not found: {model_path}\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(input_video):\n",
    "        print(f\"âŒ Video not found: {input_video}\")\n",
    "        return\n",
    "    \n",
    "    print(\"âœ… All files found!\")\n",
    "    \n",
    "    # Initialize system\n",
    "    reid_system = SingleFeedPlayerReID(model_path)\n",
    "    \n",
    "    # Process video\n",
    "    reid_system.process_video(input_video, output_video)\n",
    "    \n",
    "    print(\"\\nğŸ‰ KAGGLE RE-IDENTIFICATION COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ“‚ Output: {output_video}\")\n",
    "    print(f\"ğŸ“Š Results: {output_video.replace('.mp4', '_results.json')}\")\n",
    "    print(\"\\nâœ¨ Features:\")\n",
    "    print(\"   â€¢ LARGE VISIBLE Player IDs\")\n",
    "    print(\"   â€¢ Enhanced re-identification\")\n",
    "    print(\"   â€¢ Kaggle-optimized paths\")\n",
    "    print(\"   â€¢ Real-time processing\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7743693,
     "sourceId": 12287184,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 386742,
     "modelInstanceId": 365850,
     "sourceId": 450953,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 219.758759,
   "end_time": "2025-06-30T04:15:36.389118",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-30T04:11:56.630359",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
